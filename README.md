# Speaker Identification with ECAPA & Pyannote

## ðŸ“Œ Problem
Meetings and client calls often contain multiple speakers. Standard diarization tools can segment â€œwho spoke when,â€ but they donâ€™t *name* the speakers. This project adds a speaker-ID layer so diarized meetings can be attributed to real people.

## ðŸŒ Impact
- Automatic speaker labeling in multi-speaker meetings  
- Enrollment support: add new people with 30â€“90s of audio  
- Useful for transcription, meeting analytics, and coaching tools  

## ðŸ› ï¸ Solution
- **Embedding model:** [ECAPA-TDNN](https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb) from SpeechBrain for speaker representations  
- **Diarization:** [pyannote.audio](https://huggingface.co/pyannote/speaker-diarization) for â€œwho-spoke-whenâ€ segmentation  
- **Classifier:** Logistic Regression / SVM / kNN trained on ECAPA embeddings  
- **Enrollment:** New users can be enrolled with short audio samples and then matched in diarized meetings  
- **Evaluation:** Train/val/test splits with per-speaker accuracy reports  

## ðŸ”„ Process
1. **Preprocess audio** â†’ normalize all clips to 16 kHz mono WAV  
2. **Build manifests** â†’ CSV files with `path,label,split` metadata  
3. **Extract embeddings** â†’ ECAPA converts each clip into a vector (.npy)  
4. **Train classifier** â†’ fit Logistic Regression / SVM / kNN on embeddings  
5. **Diarize meetings** â†’ pyannote segments a conversation into speaker turns  
6. **Match speakers** â†’ nearest-centroid cosine similarity + thresholds  
7. **Summarize** â†’ Pandas DataFrames for readable reports, talk times, etc.  

## ðŸ“Š Results & Next Steps
- Achieved >90% accuracy on validation and test speakers  
- GPU acceleration reduced diarization of 4-minute audio from ~105s (CPU) to ~5s (GPU)  
- Short (<2s) segments remain challenging; rules and ASR could improve assignment  
- Next step: fuse ASR output for context-aware speaker continuity

---

## âš ï¸ Data & Environment
- **Not included:** large Kaggle datasets (50h audio) are ignored via `.gitignore`  
- **Included:** enrollment clips and demo meeting audio (small test files)  
- Requires Python 3.10+ with:
  - `speechbrain`
  - `pyannote.audio`
  - `sklearn`
  - `pandas`, `matplotlib`
  - `torchaudio`, `librosa`
  - `tqdm`

Create and activate a virtual environment, then install:

```bash
pip install -r requirements.txt
